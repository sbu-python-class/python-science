{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses keras and the tensorflow backend to do character recognition on the MNIST digits.  You need to have the `keras` and `tensorflow` packages installed.  Also for visualization of the network, you need to have `pydot` installed.\n",
    "\n",
    "We folow the example for setting up the network:\n",
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/feedforward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST data\n",
    "\n",
    "The keras library can download the MNIST data directly and provides a function to give us both the training and test images and the corresponding digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the training set consists of 60000 digits represented as a 28x28 array (there are no color channels, so this is grayscale data).  They are also integer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first digit and the \"y\" value (target) associated with it&mdash;that's the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f291212fb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"gray_r\")\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "The neural network takes a 1-d vector of input and will return a 1-d vector of output.  We need to convert our data to this form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll scale the image data to fall in [0, 1) and the numerical output to be categorized as an array.  Finally, we need the input data to be one-dimensional, so we fill flatten the 28x28 images into a single 784 vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "\n",
    "X_train = np.reshape(X_train, (60000, 784))\n",
    "X_test = np.reshape(X_test, (10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the targets (y), we need to convert the output to an array that matches what we expect the output of the neural network to be.  keras includes routines to categorize data.  In our case, since there are 10 possible digits, we want to put the output into 10 categories (represented by 10 neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the target for the first training digit.  We know from above that it was '5'.  Here we see that there is a `1` in the index corresponding to `5` (remember we start counting at `0` in python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build the neural network.  We will have 2 hidden layers, and the number of neurons will look like:\n",
    "\n",
    "784 &rarr; 500 &rarr; 300 &rarr; 10\n",
    "\n",
    "We will use a **dense** network.  This means that all neurons in one layer are connected to all neurons in the next layer (sometimes the term \"fully-connected\" is used here).\n",
    "\n",
    "For each layer, we tell keras the number of output neurons.  It infers the number of inputs from the previous layer (with the exception of the input layer, where we need to tell it what to expect as input).\n",
    "\n",
    "Also, for each layer, we specify the **activation** function.  We can use \"sigmoid\" or some other choices.  We'll use\n",
    "the the _rectified linear unit_ activation function (see http://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html#relu) for all but the last layer.  See https://keras.io/activations/ for a list of activation functions supported.\n",
    "\n",
    "Finally, for some of the layers, we will specify a **dropout**.  This means that we will ignore some of the neurons in a layer during training (randomly selected at the specified probability).  This can help present overfitting of the network.  Here's a nice discussion: https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\n",
    "\n",
    "For the very last layer (the output layer), we use a `softmax` activation.  This is commonly used with categorical data (like we have) and has the nice property that all of entries add to 1 (so we can interpret them as probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"719pt\" viewBox=\"0.00 0.00 326.00 719.00\" width=\"326pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 715)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-715 322,-715 322,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139814249873648 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139814249873648</title>\n",
       "<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 318,-710.5 318,-664.5 0,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-683.8\">dense_1_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"173,-664.5 173,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"173,-687.5 231,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"231,-664.5 231,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-695.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"231,-687.5 318,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-672.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 139814249876056 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139814249876056</title>\n",
       "<polygon fill=\"none\" points=\"33,-581.5 33,-627.5 285,-627.5 285,-581.5 33,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-600.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"140,-581.5 140,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140,-604.5 198,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"198,-581.5 198,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-612.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"198,-604.5 285,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-589.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 139814249873648&#45;&gt;139814249876056 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139814249873648-&gt;139814249876056</title>\n",
       "<path d=\"M159,-664.3799C159,-656.1745 159,-646.7679 159,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-637.784 159,-627.784 155.5001,-637.784 162.5001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139814249875048 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139814249875048</title>\n",
       "<polygon fill=\"none\" points=\"9,-498.5 9,-544.5 309,-544.5 309,-498.5 9,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-517.8\">activation_1: Activation</text>\n",
       "<polyline fill=\"none\" points=\"164,-498.5 164,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"164,-521.5 222,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-498.5 222,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-529.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"222,-521.5 309,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-506.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 139814249876056&#45;&gt;139814249875048 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139814249876056-&gt;139814249875048</title>\n",
       "<path d=\"M159,-581.3799C159,-573.1745 159,-563.7679 159,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-554.784 159,-544.784 155.5001,-554.784 162.5001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139814249874656 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139814249874656</title>\n",
       "<polygon fill=\"none\" points=\"19.5,-415.5 19.5,-461.5 298.5,-461.5 298.5,-415.5 19.5,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-434.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"153.5,-415.5 153.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"153.5,-438.5 211.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"211.5,-415.5 211.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-446.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"211.5,-438.5 298.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-423.3\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 139814249875048&#45;&gt;139814249874656 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139814249875048-&gt;139814249874656</title>\n",
       "<path d=\"M159,-498.3799C159,-490.1745 159,-480.7679 159,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-471.784 159,-461.784 155.5001,-471.784 162.5001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139814309223112 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139814309223112</title>\n",
       "<polygon fill=\"none\" points=\"33,-332.5 33,-378.5 285,-378.5 285,-332.5 33,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-351.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"140,-332.5 140,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140,-355.5 198,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"198,-332.5 198,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-363.3\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"198,-355.5 285,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-340.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 139814249874656&#45;&gt;139814309223112 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139814249874656-&gt;139814309223112</title>\n",
       "<path d=\"M159,-415.3799C159,-407.1745 159,-397.7679 159,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-388.784 159,-378.784 155.5001,-388.784 162.5001,-388.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139814309222104 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139814309222104</title>\n",
       "<polygon fill=\"none\" points=\"9,-249.5 9,-295.5 309,-295.5 309,-249.5 9,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-268.8\">activation_2: Activation</text>\n",
       "<polyline fill=\"none\" points=\"164,-249.5 164,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"164,-272.5 222,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"222,-249.5 222,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-280.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"222,-272.5 309,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-257.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 139814309223112&#45;&gt;139814309222104 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139814309223112-&gt;139814309222104</title>\n",
       "<path d=\"M159,-332.3799C159,-324.1745 159,-314.7679 159,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-305.784 159,-295.784 155.5001,-305.784 162.5001,-305.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139814332792728 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139814332792728</title>\n",
       "<polygon fill=\"none\" points=\"19.5,-166.5 19.5,-212.5 298.5,-212.5 298.5,-166.5 19.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-185.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"153.5,-166.5 153.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"153.5,-189.5 211.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"211.5,-166.5 211.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-197.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"211.5,-189.5 298.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"255\" y=\"-174.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 139814309222104&#45;&gt;139814332792728 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139814309222104-&gt;139814332792728</title>\n",
       "<path d=\"M159,-249.3799C159,-241.1745 159,-231.7679 159,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-222.784 159,-212.784 155.5001,-222.784 162.5001,-222.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139816326990480 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139816326990480</title>\n",
       "<polygon fill=\"none\" points=\"33,-83.5 33,-129.5 285,-129.5 285,-83.5 33,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-102.8\">dense_3: Dense</text>\n",
       "<polyline fill=\"none\" points=\"140,-83.5 140,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140,-106.5 198,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"198,-83.5 198,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-114.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"198,-106.5 285,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-91.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 139814332792728&#45;&gt;139816326990480 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139814332792728-&gt;139816326990480</title>\n",
       "<path d=\"M159,-166.3799C159,-158.1745 159,-148.7679 159,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-139.784 159,-129.784 155.5001,-139.784 162.5001,-139.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139814332892944 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139814332892944</title>\n",
       "<polygon fill=\"none\" points=\"12.5,-.5 12.5,-46.5 305.5,-46.5 305.5,-.5 12.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-19.8\">activation_3: Activation</text>\n",
       "<polyline fill=\"none\" points=\"167.5,-.5 167.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"167.5,-23.5 225.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"225.5,-.5 225.5,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-31.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"225.5,-23.5 305.5,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"265.5\" y=\"-8.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 139816326990480&#45;&gt;139814332892944 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>139816326990480-&gt;139814332892944</title>\n",
       "<path d=\"M159,-83.3799C159,-75.1745 159,-65.7679 159,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"162.5001,-56.784 159,-46.784 155.5001,-56.784 162.5001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify what we want to optimize and how we are going to do it.  \n",
    "\n",
    "The loss (or objective) function measures how well our predictions match the expected target (an example can be the root-mean-square of the error).  For category data, like we have, the \"cross-entropy\" metric is often used.  See here for an explanation: https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/\n",
    "\n",
    "We also need to specify an optimizer.  This could be like gradient descent.  Here's a list of the optimizers supoprted by keras: https://keras.io/optimizers/  We'll use `RMPprop`.\n",
    "\n",
    "Finally, we need to specify a metric that is evaluated during training and testing.  We'll use `\"accuracy\"` here.  This means that we'll see the accuracy of our model reported as we are training and testing.\n",
    "\n",
    "More details on these options is here: https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=rms, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "For training, we pass in the inputs and target and the number of epochs to run and it will optimize the network by adjusting the weights between the nodes in the layers.\n",
    "\n",
    "The number of epochs is the number of times the entire data set is passed forward and backward through the network.  The batch size is the number of training pairs you pass through the network at a given time.  You update the parameter in your model (the weights) once for each batch.  This makes things more efficient and less noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 0.3605 - acc: 0.8894 - val_loss: 0.1401 - val_acc: 0.9553\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.1534 - acc: 0.9537 - val_loss: 0.0963 - val_acc: 0.9695\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.1147 - acc: 0.9655 - val_loss: 0.0790 - val_acc: 0.9757\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.0937 - acc: 0.9714 - val_loss: 0.0787 - val_acc: 0.9755\n",
      "Epoch 5/20\n",
      " - 7s - loss: 0.0801 - acc: 0.9757 - val_loss: 0.0694 - val_acc: 0.9801\n",
      "Epoch 6/20\n",
      " - 6s - loss: 0.0705 - acc: 0.9790 - val_loss: 0.0756 - val_acc: 0.9788\n",
      "Epoch 7/20\n",
      " - 6s - loss: 0.0629 - acc: 0.9806 - val_loss: 0.0642 - val_acc: 0.9814\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.0582 - acc: 0.9822 - val_loss: 0.0674 - val_acc: 0.9809\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.0548 - acc: 0.9832 - val_loss: 0.0682 - val_acc: 0.9824\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.0490 - acc: 0.9851 - val_loss: 0.0674 - val_acc: 0.9836\n",
      "Epoch 11/20\n",
      " - 6s - loss: 0.0457 - acc: 0.9858 - val_loss: 0.0739 - val_acc: 0.9825\n",
      "Epoch 12/20\n",
      " - 6s - loss: 0.0447 - acc: 0.9867 - val_loss: 0.0747 - val_acc: 0.9821\n",
      "Epoch 13/20\n",
      " - 6s - loss: 0.0420 - acc: 0.9871 - val_loss: 0.0708 - val_acc: 0.9829\n",
      "Epoch 14/20\n",
      " - 6s - loss: 0.0403 - acc: 0.9884 - val_loss: 0.0729 - val_acc: 0.9829\n",
      "Epoch 15/20\n",
      " - 6s - loss: 0.0385 - acc: 0.9887 - val_loss: 0.0744 - val_acc: 0.9849\n",
      "Epoch 16/20\n",
      " - 6s - loss: 0.0357 - acc: 0.9897 - val_loss: 0.0705 - val_acc: 0.9841\n",
      "Epoch 17/20\n",
      " - 6s - loss: 0.0364 - acc: 0.9899 - val_loss: 0.0732 - val_acc: 0.9845\n",
      "Epoch 18/20\n",
      " - 6s - loss: 0.0327 - acc: 0.9904 - val_loss: 0.0769 - val_acc: 0.9849\n",
      "Epoch 19/20\n",
      " - 6s - loss: 0.0328 - acc: 0.9904 - val_loss: 0.0745 - val_acc: 0.9854\n",
      "Epoch 20/20\n",
      " - 6s - loss: 0.0326 - acc: 0.9906 - val_loss: 0.0772 - val_acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f290f646e48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 256\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "          validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "keras has a routine, `evaluate()` that can take the inputs and targets of a test data set and return the loss value and accuracy (or other defined metrics) on this data.\n",
    "\n",
    "Here we see we are > 98% accurate on the test data&mdash;this is the data that the model has never seen before (and was not trained with)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/step\n",
      "0.9852\n"
     ]
    }
   ],
   "source": [
    "loss_value, accuracy = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting\n",
    "\n",
    "Suppose we simply want to ask our neural network to predict the target for an input.  We can use the `predict()` method to return the category array with the predictions.  We can then use `np.argmax()` to select the most probable.  Alternately, we can use `predict_classes()` to return the class (index) with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's loop over the test set and print out what we predict vs. the true answer for those we get wrong.  We can also plot the image of the digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 115: prediction = 9, truth is 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD+CAYAAADxoQNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAADP9JREFUeJzt3W+oVHUex/HP92amaNFGc1MIurDSFku3hSbZiKyN4sL6INGVhHpSuBeCtNKIJfvzpAWVNauFiPukFoR9YFFQEf1BJEIqBoxdqgfFYpiCO9lCe9XC9LsPPO3etTu/M50558zR7/sF4u+e7zlzvv3i42/unJk55u4CEMfIsBsAUC9CDwRD6IFgCD0QDKEHgiH0QDCEHgiG0APBEHogmDl1nejiiy/2sbGxuk4HhLNv3z599dVXlrdfbaEfGxtTp9Op63RAOO12u6/9Cj+9N7PHzGyFmW0q+hgA6lco9GZ2iyRz91cknWtmy8ptC0BViq7010vam433Srp5tp3MbNLMOmbW6Xa7BU8FoExFQz8q6Ug2npa0aLad3H3K3dvu3m61WgVPBaBMRUM/IulENj5nxhhAwxUN/SFJC7LxBZJ47g6cIYqG/j1J49l4qaT3y2kHQNWKhn6XpJaZrc5+frOkfgBUrNCbc9z9pKQN2Y87y2sHQNV47z0QDKEHgiH0QDCEHgiG0APBEHogGEIPBEPogWAIPRAMoQeCIfRAMIQeCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4Ipra71uLs89xzzyXr99xzT8/aSy+9lDx25cqVhXpCPlZ6IBhCDwRD6IFgCD0QDKEHgiH0QDCEHgiG6/To6dlnn03W77333sKPff755xc+FoMpvNKb2bidssTM5pfZFIDqDPL0frekg5Juc/dj5bQDoGqDPL1f7+47SusEQC0GWenbZrbczB7stYOZTZpZx8w63W53gFMBKMsgod/o7q9L+tbMJmbbwd2n3L3t7u1WqzXAqQCUpVDozewuSXdnPx6TNF5aRwAqVfR3+sOSPszGY5LeLaUbAJUrGvrXJK0zs39LOuDub5fYE2qyZ8+eZP2+++5L1s8777xkfceO3q/z3nrrrcljUZ1CoXf3k5KeLrkXADXgbbhAMIQeCIbQA8EQeiAYQg8Ew0drz2KffPJJsr5mzZqBHn/r1q3J+qpVqwZ6fFSDlR4IhtADwRB6IBhCDwRD6IFgCD0QDKEHguE6/Rlu3759PWsTE7N+odF/HTx4MFnfvn17sr5u3bpkHc3ESg8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwXCdvuG+//77ZH3Dhg09awcOHEge+8ADDyTr69evT9YHceLEiWR9ZCS9HplZme2EwkoPBEPogWAIPRAMoQeCIfRAMIQeCIbQA8Fwnb7hnnrqqWT95Zdf7lnL+177bdu2FeqpXydPnuxZy+st77sA1q5dW6gn9LnSm9mImW0/bdtjZrbCzDZV0xqAKuSG3swuknS/pBtnbLtFkrn7K5LONbNl1bUIoEy5oXf3r939SUnfzNh8vaS92XivpJsr6A1ABYq+kDcq6Ug2npa0aLadzGzSzDpm1ul2uwVPBaBMRUM/IumHT0ycM2P8f9x9yt3b7t5utVoFTwWgTEVDf0jSgmx8gSSWceAMUTT070kaz8ZLJb1fTjsAqpZ7nd7MFkr6vaQrzWyDpClJuyT91sxWZ7u9WV2LZ7cvvvgiWX/mmWeS9auuuqpn7fHHHy/UU1m+/PLLnrUXX3wxeeynn36arN95553J+rx585L1yHJD7+7TkrZnf2b64dsbdpbdFIDq8DZcIBhCDwRD6IFgCD0QDKEHguGjtUO2efPmZH3//v3J+saNG3vWrrjiikI99ev48ePJ+qZNxT+AeckllyTrXJIrjpUeCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4LhOn3FPv/882T9+eefT9aXL1+erFd5O+k8ee8h2LFjR+HHXrFiReFjkcZKDwRD6IFgCD0QDKEHgiH0QDCEHgiG0APBcJ2+Yq+++mqy/t133yXrqds9D9vOndV9EfLq1avzd0IhrPRAMIQeCIbQA8EQeiAYQg8EQ+iBYAg9EAzX6Ss2MTGRrM+Zk/5f8MYbbyTrq1at6ll7+OGHk8e22+1k/bPPPkvWn3jiiWQ9Ze3atcn66Oho4cdGWl8rvZmNmNn207aN2ylLzGx+Ne0BKFtu6M3sIkn3S7rxtNJuSQcl3ebux8pvDUAVckPv7l+7+5OSvjmttN7dF7v7tmpaA1CFQV7Ia5vZcjN7sNcOZjZpZh0z63S73QFOBaAsg4R+o7u/LulbM5v11Sp3n3L3tru3W63WAKcCUJZCoTezuyTdnf14TNJ4aR0BqFTRS3aHJX2YjcckvVtKNwAqZ+6e3sFsoaTfS/qDpC2SpiQdlbRO0r8lzXX35/JO1G63vdPpDNzw2SbvWvejjz5a+LEvvPDCZH3p0qXJ+p49e5L16enpZH1kpPcTyQMHDiSPXbRoUbKOH2u32+p0Opa3X+5K7+7TkrZnf2Z6umBvAIaIt+ECwRB6IBhCDwRD6IFgCD0QDB+tHbJHHnkkWV+yZEmy/tBDD/Ws5d1K+q233krWB7Vs2bKeNS7JDQ8rPRAMoQeCIfRAMIQeCIbQA8EQeiAYQg8Ew3X6hluzZk2yvnLlyp61EydOJI/9+OOPk/Vrr702WV+wYEGy/sILLyTrGA5WeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4Ihuv0Z7i5c+cWPjbvK6zzLF68OFm/7LLLBnp8VIOVHgiG0APBEHogGEIPBEPogWAIPRAMoQeC4Tp9YFu3bh3o+ImJiZI6QZ1yQ29mcyVNSponaY67b862Pybpb5J+6e5/rLRLAKXpZ6X/naS/uvthM3vRzH4taaEkc/dXzOxXZrbM3d+ttlUAZejnd/pfSLo9G/9D0qWSrpe0N9u2V9LN5bcGoAr9hH6LpL9k46slfSBpVNKRbNu0pFlvTGZmk2bWMbNOt9sdtFcAJcgNvbsfdfcjZnaDpF3uvj877odvXTxnxvj0Y6fcve3u7VarVVrTAIrr65Kdmf1M0g3uviXbdEjSD1+FeoEklnHgDNHvJbs1kraY2RxJN0l6T9K1kl6XtFTSrkq6w0A++uijZP2dd96pqRM0Se5Kb2aTkjbr1Or+z+zvXZJaZrY62+3NyjoEUKrcld7dpyRNzVLakP29s9SOAFSKt+ECwRB6IBhCDwRD6IFgCD0QDB+tPYvlfcX18ePHk/WFCxcm63fcccdP7gnDx0oPBEPogWAIPRAMoQeCIfRAMIQeCIbQA8Fwnf4sNjo6mqzPnz8/Wb/mmmuS9euuu+4n94ThY6UHgiH0QDCEHgiG0APBEHogGEIPBEPogWC4Tn8Wu/zyy5P1o0eP1tQJmoSVHgiG0APBEHogGEIPBEPogWAIPRAMoQeCIfRAMLlvzjGzuZImJc2TNMfdN2fbxyX9XdLPJR1w92NVNgqgHP2s9L+T9Fd3/5Oktpn9Otu+W9JBSbcReODM0U/ofyHp9mz8D0mXZuP17r7Y3bf1OtDMJs2sY2adbrc7YKsAytBP6LdI+ks2vlrSB9m4bWbLzezBXge6+5S7t9293Wq1BmwVQBlyQ+/uR939iJndIGmXu+/PShvd/XVJ35rZRKVdAihNX6/em9nPJN3g7luyn++SdHdWPiZpvJr2AJSt34/WrpG0xczmSLpJ0mFJH2a1MUnvlt4ZgErkrvRmNilps6RDkv6Z/f2apNvN7G6dulz3dqVdAihN7krv7lOSpmYpPV1+OwCqxjvygGAIPRAMoQeCIfRAMIQeCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4Ixty9nhOZdSV9MWPTxZK+quXkP11Te2tqXxK9FVVmb5e5e+730tUW+h+d2Kzj7u2hnDxHU3tral8SvRU1jN54eg8EQ+iBYIYZ+tm+jacpmtpbU/uS6K2o2nsb2u/0AIaDp/dAMIQeCIbQA8HUHnoze8zMVpjZprrPncfMxu2UJWY2f9j9SJKZjZjZ9tO2DX0Oe/Q19Pkzs7lmdq+ZPWhmf5ixvQlz1qu3Wuet1tCb2S069eLhK5LONbNldZ6/D7vVoNtvm9lFku6XdOOMbUOfw9n6yuzW8OfvR7dWb8Kc9eot275bNc5b3Sv99ZL2ZuO9km6u+fx5cm+/XSd3/9rdn5T0zYzNQ5/DHn1JzZi/2W6tPvQ5yxS+7XuZ+r2XXVlGJR3JxtOSFtV8/jxtM/uXpCuzf42bqMlz2IT52yLJsvHVkv4s6TdqxpzN1ptU87zVvdKPSDqRjc+ZMW6KM+H2202ew6HPX49bqzdizppy2/e6Q39I0oJsfIGkbs3n7+kMuv12I+ewSfN3+q3V1aA5a8Jt3+sO/Xv633/UUknv13z+lMOSXs3GY5I+Gl4rSU2dwybN339vrZ69iNekOTu9t9rnre7Q75LUMrPV2c9v1nz+lMbdftvMFprZA5KuNLMNZrZQDZjDHn01Yv563Fp96HOW6K32eeO990AwvCMPCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAw/wEw61Tjpq+oLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28afe7d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 151: prediction = 8, truth is 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28afcacd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 247: prediction = 2, truth is 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28afcc3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 321: prediction = 7, truth is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD+CAYAAADxoQNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAADO5JREFUeJzt3XuIXGWax/HfL0adaFAmWpKBMTasMoSFjmCpA8FkvEBgFbwwIYP+oRGmQdkRN14YSLwhq2nYGEX8w0YRQRzEVQTjH0FogihxtKHXXVE0MCiDYqZMRpxcFC/P/pEzuz2ZrlM9p05Vnfh8PxD67fPUqfP4ws+3u9+qOo4IAchj0agbADBchB5IhtADyRB6IBlCDyRD6IFkCD2QDKEHkiH0QDKLh3Wh008/PcbGxoZ1OSCdjz76SJ9//rl7PW5ooR8bG9PMzMywLgek0263F/S4yj/e277b9lW2N1d9DgDDVyn0ti+T5Ih4SdLxttfU2xaAQam60q+WNFuMZyVdMt+DbE/YnrE90+l0Kl4KQJ2qhv4MSQeL8QFJy+d7UERMRUQ7ItqtVqvipQDUqWroF0n6rhgfN2cMoOGqhn6vpJOL8SmS+NkdOEZUDf3rksaL8QWS3qynHQCDVjX005JattcX3++sqR8AA1bpxTkR8b2kTcW3z9fXDoBB47X3QDKEHkiG0APJEHogGUIPJEPogWQIPZAMoQeSIfRAMoQeSIbQA8kQeiAZQg8kQ+iBZAg9kAyhB5Ih9EAyhB5IhtADyRB6IBlCDyRD6IFkCD2QDKEHkiH0QDKEHkiG0APJEHogGUIPJFM59LbHfcTZtpfU2RSAwelnpd8l6VNJV0bE4XraATBole5PX7glIp6prRMAQ9HPSt+2fbnt27s9wPaE7RnbM51Op49LAahLP6G/LSJekfSV7XXzPSAipiKiHRHtVqvVx6UA1KVS6G1vlHRj8e1hSeO1dQRgoKr+Tr9P0lvFeEzSa7V0A2DgqoZ+h6Tf2P6LpE8i4tUae8IcX3zxRWl9z549XWvPPvtsX9d++OGHS+u2+3r+MsuXLy+t7969u7R+1lln1dnOD0ql0EfE95IeqbkXAEPAK/KAZAg9kAyhB5Ih9EAyhB5Ipp/X3qMGzzxT/vaFBx54oLT+wQcf1NnO3+i1Jbdq1arS+jfffNO19v7775eeu3fv3tL6Z599Vlpny647VnogGUIPJEPogWQIPZAMoQeSIfRAMoQeSIZ9+gHr9fbWm266qbR+6NCh0vqyZcu61q655prSc3vts69Zs6a03msv/Ntvv+1aO/PMM0vPPXy4/LNWe83rhRdeWFrPjJUeSIbQA8kQeiAZQg8kQ+iBZAg9kAyhB5Jhn75PvfbRn3jiidL6eeedV1rfsmVLaX316tVda0uWjPZmwmV77f1+fPb69ev7Oj8zVnogGUIPJEPogWQIPZAMoQeSIfRAMoQeSIZ9+j6ddNJJpfXp6ekhddI827Zt61rr9fqGc845p7S+cuXKSj1hgSu97UW2tx917G7bV9nePJjWAAxCz9DbXibpVklr5xy7TJIj4iVJx9su/4gVAI3RM/QRsT8iHpL05ZzDqyXNFuNZSZcMoDcAA1D1D3lnSDpYjA9IWj7fg2xP2J6xPdPpdCpeCkCdqoZ+kaTvivFxc8Z/IyKmIqIdEe1Wq1XxUgDqVDX0eyWdXIxPkcQyDhwjqob+dUnjxfgCSW/W0w6AQeu5T297qaRfS1ppe5OkKUnTkv7F9l/f1LxzcC2iqd5+++3S+uTkZOXn7nU/gNNOO63yc2fXM/QRcUDS9uLfXJuKr8/X3RSAweFluEAyhB5IhtADyRB6IBlCDyTDW2vR1ffff19a37mzfKe27O2zp556aum5F198cWkd1bHSA8kQeiAZQg8kQ+iBZAg9kAyhB5Ih9EAy7NOjqyeffLK0fs8991R+7q1bt5bWx8fHS+uojpUeSIbQA8kQeiAZQg8kQ+iBZAg9kAyhB5Jhnx5d7dixo6/zV6xY0bV2/fXX9/XcqI6VHkiG0APJEHogGUIPJEPogWQIPZAMoQeSYZ8+sdnZ2dL6yy+/XFq3XVq/4447utZOPPHE0nMxOAta6W0vsr39qGPjPuJs20sG0x6AuvUMve1lkm6VtPao0i5Jn0q6MiIO198agEHoGfqI2B8RD0n68qjSLRHxk4jYNpjWAAxCP3/Ia9u+3Pbt3R5ge8L2jO2ZTqfTx6UA1KWf0N8WEa9I+sr2uvkeEBFTEdGOiHar1erjUgDqUin0tjdKurH49rAkProUOEZU3bLbJ+mtYjwm6bVaugEwcD1Db3uppF9LWml7k6QpSTsk/cb2XyR9EhGvDrZNVHHw4MHS+r333ltaj4jS+qWXXlpav/nmm0vrGI2eoY+IA5K2F//memQgHQEYKF6GCyRD6IFkCD2QDKEHkiH0QDK8tfYH7Kmnniqt9/qI6yVLyt88uXHjxn+4J4weKz2QDKEHkiH0QDKEHkiG0APJEHogGUIPJMM+/TFuz549XWubN2/u67nLPsJakq699tq+nh+jwUoPJEPogWQIPZAMoQeSIfRAMoQeSIbQA8mwT99wvT6G+sEHH+xaO3DgQF/XvuKKK/o6H83ESg8kQ+iBZAg9kAyhB5Ih9EAyhB5IhtADybBP33AvvPBCaf3pp5+u/Nw33HBDaf3888+v/NxoroXcn/4ESROSfiRpcURsLY7fLem/Jf1zRPz7QLsEUJuFrPS/lPS7iNhn+z9t/1zSUkmOiJdsn2t7TUS8NthWAdRhIb/T/0zShmL8B0k/lbRa0mxxbFbSJfW3BmAQFhL6SUl//cVxlaTfSzpD0sHi2AFJy+c70faE7RnbM51Op99eAdSgZ+gj4lBEHLR9kaTpiPhjcd53xUOOmzM++typiGhHRLvVatXWNIDqFrRlZ/vHki6KiMni0F5JJxfjUySxjAPHiIVu2f1K0qTtxZJ+Iel1SedLekXSBZKmB9Id9OGHHw7subds2TKw5+7lueeeK61v2LChtI7qeq70tickbdWR1f1PxddpSS3b64uH7RxYhwBq1XOlj4gpSVPzlDYVX5+vtSMAA8XLcIFkCD2QDKEHkiH0QDKEHkiGt9Y23MzMTOVz77rrrtL6ihUrSutff/11af3FF18srd9///1da48++mjpuRgcVnogGUIPJEPogWQIPZAMoQeSIfRAMoQeSIZ9+obbvXt35XP3799fWn/vvfdK69ddd11p/eOPPy6tb968uWtt7dq1pedicFjpgWQIPZAMoQeSIfRAMoQeSIbQA8kQeiAZ9ukb7uqrry6tP/74411rjz32WOm5veoRUVqfmJgord95552ldYwGKz2QDKEHkiH0QDKEHkiG0APJEHogGUIPJMM+fcPdd999pfU33nija+3dd98tPffcc88trfe6f/26detK62imnqG3fYKkCUk/krQ4IrYWx8cl/Y+kf5L0SUQcHmSjAOqxkB/vfynpdxHxH5Latn9eHN8l6VNJVxJ44NixkND/TNKGYvwHST8txrdExE8iYlu3E21P2J6xPdPpdPpsFUAdFhL6SUlPF+NVkn5fjNu2L7d9e7cTI2IqItoR0W61Wn22CqAOPUMfEYci4qDtiyRNR8Qfi9JtEfGKpK9s8xcd4BixoC072z+WdFFETBbfb5R0Y1E+LGl8MO0BqNtCt+x+JWnS9mJJv5C0T9JbRW1M0mu1dwZJUq9fi955550hdYIfip4rve0JSVsl7ZX0p+LrDkkbbN+oI9t1rw60SwC16bnSR8SUpKl5So/U3w6AQeNluEAyhB5IhtADyRB6IBlCDyRD6IFkCD2QDKEHkiH0QDKEHkiG0APJEHogGUIPJONetyOu7UJ2R9LHcw6dLunzoVz8H9fU3pral0RvVdXZ21kR0fNz6YYW+r+7sD0TEe2RXLyHpvbW1L4keqtqFL3x4z2QDKEHkhll6Of7NJ6maGpvTe1Loreqht7byH6nBzAa/HgPJEPogWQIPZDM0ENv+27bV9nePOxr92J73EecbXvJqPuRJNuLbG8/6tjI57BLXyOfP9sn2P5X27fb/u2c402Ys269DXXehhp625fpyB8PX5J0vO01w7z+AuxSg26/bXuZpFslrZ1zbORzOF9fhV0a/fz93a3VmzBn3Xorju/SEOdt2Cv9akmzxXhW0iVDvn4vPW+/PUwRsT8iHpL05ZzDI5/DLn1JzZi/+W6tPvI5K1S+7XudFnovu7qcIelgMT4gafmQr99L2/afJa0s/m/cRE2ewybM36QkF+NVkh6VdLGaMWfz9SYNed6GvdIvkvRdMT5uzrgpjoXbbzd5Dkc+f11urd6IOWvKbd+HHfq9kk4uxqdI6gz5+l0dQ7ffbuQcNmn+jr61uho0Z0247fuwQ/+6/v8/6gJJbw75+mX2SXq5GI9J+q/RtVKqqXPYpPn7v1urF3/Ea9KcHd3b0Odt2KGfltSyvb74fueQr1+mcbfftr3U9r9JWml7k+2lasAcdumrEfPX5dbqI5+zkt6GPm+89h5IhlfkAckQeiAZQg8kQ+iBZAg9kAyhB5Ih9EAyhB5I5n8BiN1dI1v/2+AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f290f739438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 340: prediction = 3, truth is 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28d4f086d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 445: prediction = 0, truth is 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP0AAAD+CAYAAADxoQNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAADaNJREFUeJzt3W+IXGWWx/Hf6SQSSRAm2CHRQRu3cZDVzkpqw4CknVUhoqh5MWJeiMGGaUE3nWxUDAr+AyUtq0EXFRsRBv/kRRSEVVAisRGFJJT0mvWV0YmbYLCnE1cy3RMVMmdf5Drb09P13LLq3qobz/cDoZ+6p27fk4f8cqv7qbrX3F0A4ujpdgMAOovQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4IZmGnDnTuued6X19fpw4HhPPll1/q2LFjlve8joW+r69P9Xq9U4cDwqnVak09r+WX92b2oJmtN7MHWv0eADqvpdCb2TWSzN3flLTIzAaLbQtAWVo9018haSIbT0i6ar4nmdmwmdXNrD41NdXioQAUqdXQL5c0k42nJa2Y70nuPubuNXev9fb2tngoAEVqNfQ9kk5l4wWzxgAqrtXQT0pako3PkcRrd+AM0WroP5Q0kI3XSNpbTDsAytZq6PdI6jWzm7PH7xbUD4CStfTmHHf/i6St2cNdxbUDoGy89x4IhtADwRB6IBhCDwRD6IFgCD0QDKEHgiH0QDCEHgiG0APBEHogGEIPBEPogWAIPRAMoQeCIfRAMIQeCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwRB6IBhCDwTT0g0sUR3PPPNMw9rIyEgHO8GZouUzvZkN2Gn9ZnZ2kU0BKE87L+/HJR2VdJO7nyymHQBla+fl/Yi7v1JYJwA6op0zfc3Mrjezexo9wcyGzaxuZvWpqak2DgWgKO2E/m53f1vSd2a2br4nuPuYu9fcvdbb29vGoQAUpaXQm9ntkoayhyclDRTWEYBStfoz/XFJ+7Nxn6QPCukGQOlaDf1bkjaZ2Z8kfeXuuwvsKZSZmZlkfdu2bcn6oUOHGtZYp8d8Wgq9u/9F0tMF9wKgA3gbLhAMoQeCIfRAMIQeCIbQA8Hw0douSy25SdKzzz6brO/fvz9ZB+biTA8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwbBO32WbN29O1i+77LJkffHixUW2gwA40wPBEHogGEIPBEPogWAIPRAMoQeCIfRAMKzTl2z37vTVwU+dOpWsf/LJJ0W201FffPFFw9q3336b3Hf16tXJ+vvvv5+sf/TRR8l6O1atWpWs33DDDaUduwic6YFgCD0QDKEHgiH0QDCEHgiG0APBEHogGNbpS/bOO+8k6z093ft/9+jRo8n6+vXr2/r+J06caFj7/vvvk/uef/75yfqxY8eS9c8++yxZb0dvb2+yfuGFFybr3b5XQVP/4sysx8x2zNn2oJmtN7MHymkNQBlyQ29myyRtkXTlrG3XSDJ3f1PSIjMbLK9FAEXKDb27f+PuT0ma/VrtCkkT2XhC0lUl9AagBK3+QLlc0kw2npa0Yr4nmdmwmdXNrD41NdXioQAUqdXQ90j68ZMiC2aN/4a7j7l7zd1reb/8ANAZrYZ+UtKSbHyOJE7jwBmi1dB/KGkgG6+RtLeYdgCULXed3syWSvqdpEvMbKukMUl7JF1nZjdnT3u3vBarLW+t+8CBA8n6iy++mKzX6/Vk/YILLmhYW758eXLfoaGhZD21zi5J7p6sHzx4MFlP2bhxY7Kedx2Cxx57rOVj58n7/dSaNWtKO3YRckPv7tOSdmR/Ztuafd1VdFMAysPbcIFgCD0QDKEHgiH0QDCEHgiGj9a26dZbb03Wx8fHk/U77rgjWT98+HCy/uqrrzas5S3ZLVmyJFnftSu9MJO3ZDc5OZmspwwOpj/DdeTIkWT99ddfb1g7dOhQct8ffvghWb/22muT9ZdeeilZ7zbO9EAwhB4IhtADwRB6IBhCDwRD6IFgCD0QDOv0Tdi3b1/DWt5HXy+//PJkffv27cn6k08+mawvW7YsWU954403Wt632/r7+5P11GWm77rrruS+r7zySrK+cuXKZL3qV4niTA8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwbBO34QXXnihYW16ejq5b97n7VevXp2sv/baa8k65pf6LH/eOvzPHWd6IBhCDwRD6IFgCD0QDKEHgiH0QDCEHgiGdXpJjz76aLKeWtddu3Ztct9Nmza11BPSHn744WR9dHS0YW3Lli3JfR9//PFkfcGCBcl61TV1pjezHjPbMWfbgJ3Wb2Znl9MegKLlht7MlknaIunKOaVxSUcl3eTuJ4tvDUAZckPv7t+4+1OSTswpjbj7SndPX88JQKW084u8mpldb2b3NHqCmQ2bWd3M6lNTU20cCkBR2gn93e7+tqTvzGzdfE9w9zF3r7l7reoXCwSiaCn0Zna7pKHs4UlJA4V1BKBUrS7ZHZf04zWG+yR9UEg3AEqXG3ozWyrpd5IuMbOtksYkvSVpk5n9SdJX7r673DbL9dBDDyXrZtaw1tOTfrG0cCFvhWjF/fffn6zv3p3+J3ffffc1rK1bN+9Po3+1ePHiZP1Ml/sv0t2nJe3I/sz2dCkdASgVb8MFgiH0QDCEHgiG0APBEHogGNaT2nTixNyPJPytr7/+OllfsWJFke1USuo23s8//3xy35dffjlZz7td9G233dawdtFFFyX3/bnjTA8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwbBO36aJiYlkfePGjcn6zp07k/Vly5b95J6KcuDAgWR9165dyfoTTzzRsHbdddcl9827xPXg4GCyHn0tPoUzPRAMoQeCIfRAMIQeCIbQA8EQeiAYQg8Ewzq9pP7+/mQ9dUuuvM/T512qecOGDcn6c889l6zfe++9DWuff/55ct88eX+3kZGRZP3jjz9uWDvvvPOS+3bz/Qk/d5zpgWAIPRAMoQeCIfRAMIQeCIbQA8EQeiAY1uklHTx4MFkfGhpqWFu6dGly37179ybr7733XrJ+8cUXJ+vtWLRoUbK+efPmZP3qq69O1i+99NKf3BPK18z96c+SNCxpsaSF7r492/6gpAOS/tHdHyu1SwCFaeZM/1tJO939uJm9bma/lrRUkrn7m2b2T2Y26O4flNsqgCI08zP9ryTdko3/IOmXkq6Q9ON1oiYkXVV8awDK0EzoRyX9PhuvkrRP0nJJM9m2aUnz3pDNzIbNrG5m9dT71wF0Tm7o3f3P7j5jZmsl7XH3I9l+p7KnLJg1nrvvmLvX3L3W29tbWNMAWtfUkp2Z/ULSWncfzTZNSlqSjc+RxGkcOEM0u2S3QdKomS2U9BtJH0r6Z0lvS1ojaU8p3VXEtm3bGtbyLrV8+PDhZP3GG29M1icnJ5P1djzyyCPJ+p133lnasdE9uWd6MxuWtF2nz+5/zL7ukdRrZjdnT3u3tA4BFCr3TO/uY5LG5iltzb6m73gAoFJ4Gy4QDKEHgiH0QDCEHgiG0APB8NHaJrTz8da8dfxPP/205e8NtIIzPRAMoQeCIfRAMIQeCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwRB6IBhCDwRD6IFgCD0QDKEHgiH0QDCEHgiG0APBEHogGEIPBEPogWByb3ZhZmdJGpa0WNJCd9+ebR+Q9N+S/kHSV+5+ssxGARSjmTP9byXtdPd/l1Qzs19n28clHZV0E4EHzhzNhP5Xkm7Jxn+Q9MtsPOLuK939yUY7mtmwmdXNrD41NdVmqwCK0EzoRyX9PhuvkrQvG9fM7Hozu6fRju4+5u41d6/19va22SqAIuSG3t3/7O4zZrZW0h53P5KV7nb3tyV9Z2brSu0SQGGa+u29mf1C0lp3H80e3y5pKCuflDRQTnsAitbsrao3SBo1s4WSfiPpuKT9Wa1P0geFdwagFLlnejMblrRd0qSkP2Zf35J0i5kN6fRy3e5SuwRQmNwzvbuPSRqbp/R08e0AKBvvyAOCIfRAMIQeCIbQA8EQeiAYQg8EQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwRB6IBhz984cyGxK0v/M2nSupGMdOfhPV9XeqtqXRG+tKrK3C90997p0HQv93x3YrO7uta4cPEdVe6tqXxK9taobvfHyHgiG0APBdDP0812Npyqq2ltV+5LorVUd761rP9MD6A5e3gPBEHogGEIPBNPx0JvZg2a23swe6PSx85jZgJ3Wb2Znd7sfSTKzHjPbMWdb1+ewQV9dnz8zO8vM/tXM7jGzbbO2V2HOGvXW0XnraOjN7Bqd/uXhm5IWmdlgJ4/fhHFV6PbbZrZM0hZJV87a1vU5nK+vzLi6P39/d2v1KsxZo96y7ePq4Lx1+kx/haSJbDwh6aoOHz9P7u23O8ndv3H3pySdmLW563PYoC+pGvM3363Vuz5nmZZv+16kZu9lV5Tlkmay8bSkFR0+fp6amf2vpEuy/42rqMpzWIX5G5Vk2XiVpP+Q9C+qxpzN15vU4Xnr9Jm+R9KpbLxg1rgqzoTbb1d5Drs+fw1urV6JOavKbd87HfpJSUuy8TmSpjp8/IbOoNtvV3IOqzR/c2+trgrNWRVu+97p0H+o//9LrZG0t8PHTzku6T+zcZ+k/+peK0lVncMqzd9fb62e/RKvSnM2t7eOz1unQ79HUq+Z3Zw9frfDx0+p3O23zWypmf2bpEvMbKuZLVUF5rBBX5WYvwa3Vu/6nCV66/i88d57IBjekQcEQ+iBYAg9EAyhB4Ih9EAwhB4IhtADwRB6IJj/Aw38ljQKF4s/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f290f79c710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 447: prediction = 9, truth is 4\n",
      "stopping\n"
     ]
    }
   ],
   "source": [
    "for n, (x, y) in enumerate(zip(X_test, y_test)):\n",
    "    try:\n",
    "        res = model.predict(np.array([x]), verbose=0)\n",
    "        if np.argmax(res) != np.argmax(y):\n",
    "            print(\"test {}: prediction = {}, truth is {}\".format(n, np.argmax(res), np.argmax(y)))\n",
    "            plt.imshow(x.reshape(28, 28), cmap=\"gray_r\")\n",
    "            plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"stopping\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Batch size\n",
    "\n",
    "Adjust the batch size&mdash;how does this affect the time it takes to train for an epoch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Hidden layers\n",
    "\n",
    "Remove one of the hidden layers&mdash;how does the accuracy change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Dropout\n",
    "\n",
    "What happens to the accuracy if you don't include any dropouts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Activation\n",
    "\n",
    "How does the network perform using a `\"sigmoid\"` activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Callbacks\n",
    "\n",
    "keras allows for callbacks each epoch to store some information.  Make a plot of the accuracy vs. epoch by adding a callback.  Take a look here for some inspiration:\n",
    "\n",
    "https://keras.io/callbacks/#example-recording-loss-history\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Further\n",
    "\n",
    "Convolutional neural networks are often used for image recognition, especially with larger images.  They use filter to try to recognize patterns in portions of images (A tile).  See this for a keras example: http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
